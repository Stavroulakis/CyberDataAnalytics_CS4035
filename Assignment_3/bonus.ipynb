{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DaTaset (Scenario 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import  tree\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "columns=['StartTime','Duration', 'Protocol', 'Source','Direction','Dest', 'Flag','Tos','Packet' ,'Bytes','Flows','Label']\n",
    "lst=[]\n",
    "with open('capture20110818.pcap.netflow.labeled') as fp:  \n",
    "    for cnt, line in enumerate(fp):\n",
    "        k=[]\n",
    "        if cnt!=0:\n",
    "            dat=line.split(\"\\t\")\n",
    "            if len(dat)>=13:\n",
    "                for d in dat:\n",
    "                    d.strip()\n",
    "                    if len(d)==0:\n",
    "                        k = dat.remove(d)\n",
    "            if k:\n",
    "                lst.append(k)\n",
    "            else: lst.append(dat)\n",
    "dataset=pd.DataFrame(lst, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Proccess the dataset ( Remove Background, make some fields type int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove background\n",
    "dataset=dataset.loc[dataset.Label!='Background\\n']\n",
    "# fill empty values with 0\n",
    "dataset=dataset.fillna(0)\n",
    "#convert some columns to int\n",
    "dataset.Tos=dataset.Tos.astype(int)\n",
    "dataset['Packet']=dataset['Packet'].astype(int)\n",
    "dataset['Bytes']=dataset['Bytes'].astype(int)\n",
    "dataset.Flows=dataset.Flows.astype(int)\n",
    "#Drop labels that are 0 ( since before was nan)\n",
    "dataset=dataset.loc[dataset.Label!=0]\n",
    "\n",
    "# convert Starttime into datatime  and set StartTime as indexes in the dataframe\n",
    "dataset.StartTime=pd.to_datetime(dataset.StartTime)\n",
    "dataset=dataset.set_index(dataset.StartTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new columns in the dataset (split ips and ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### extract ports\n",
    "def ip(data):\n",
    "    return data.split(':')[0]\n",
    "def port(data):\n",
    "    if len(data.split(':'))>1:\n",
    "        return data.split(':')[1]\n",
    "    else:\n",
    "        return(' ')\n",
    "\n",
    "dataset['SourceIP']=dataset['Source'].apply(lambda x: ip(x))\n",
    "dataset['SourcePort']=dataset['Source'].apply(lambda y: port(y))\n",
    "dataset['DestIP']=dataset['Dest'].apply(lambda x: ip(x))\n",
    "dataset['DestPort']=dataset['Dest'].apply(lambda y: port(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of BClus detection method (aggregate netflows by source ip address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "begin=dataset.index[0]\n",
    "end=dataset.index[0]\n",
    "#the new aggregate dataset\n",
    "new_dataset=pd.DataFrame()\n",
    "#while loop till end\n",
    "while begin in dataset.index:\n",
    "    #take two minutes time window\n",
    "    end=begin+datetime.timedelta(minutes=2)\n",
    "    window =dataset.loc[ (dataset.index>=begin) & (dataset.index<=end)]\n",
    "    #remaining dataset\n",
    "    remain=dataset.loc[dataset.index> end]\n",
    "    #loop for inner time window inside time window\n",
    "    begin1=begin\n",
    "    for i in range(0,2):\n",
    "        end1=begin1+datetime.timedelta(minutes=1)\n",
    "        window1 =window.loc[ (window.index>=begin1) & (window.index<=end1)]\n",
    "        #do aggregations\n",
    "        group = window1.groupby('SourceIP')\n",
    "        agg = group.aggregate({'Packet': np.sum,'Bytes':np.sum,'Flows':np.sum,'Tos':np.sum})\n",
    "        agg['Destinations'] = window1.groupby('SourceIP').Dest.nunique()\n",
    "        agg['SourcePorts'] = window1.groupby('SourceIP').SourcePort.nunique()\n",
    "        agg['DestPorts'] = window1.groupby('SourceIP').DestPort.nunique()\n",
    "        new_dataset=new_dataset.append(agg, ignore_index=False)\n",
    "        begin1=end1\n",
    "    if len(remain)==0:\n",
    "        break;\n",
    "    else:\n",
    "        begin=remain.index[0]\n",
    "\n",
    "#reset index in the new dataset\n",
    "new_dataset=new_dataset.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign labels to the new dataset ( 1 for infected host, 0 else, based on the infected host as described in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def label(data):\n",
    "    infected={'147.32.84.165','147.32.84.191','147.32.84.192','147.32.84.193','147.32.84.204',\n",
    "             '147.32.84.205','147.32.84.206','147.32.84.207','147.32.84.208','147.32.84.209'}\n",
    "    if data in infected:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "new_dataset['Label']=new_dataset['SourceIP'].apply(lambda y: label(y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into test and train, apply SMOTE for the imbalance problem ,create the different classifiers and make the classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using RandmomForest on Packet Level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative 4118.6\n",
      "False Positive 10.8\n",
      "False Negative 15.1\n",
      "True Positive 211.5\n",
      "-------------\n",
      "Precision : 0.9518236137029736\n",
      "Recall :  0.9338232297915587\n",
      "Accuracy :  0.9940541781450871\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#store ips of the new dataset\n",
    "ips=new_dataset.SourceIP\n",
    "#drop ips for the final dataset\n",
    "final_dataset_packet=new_dataset.drop('SourceIP',axis=1)\n",
    "\n",
    "TN=[]\n",
    "FP=[]\n",
    "FN=[]\n",
    "TP=[]\n",
    "Precision=[]\n",
    "Recall=[]\n",
    "Accuracy=[]\n",
    "for i in range(0,10):\n",
    "    classifier=RandomForestClassifier()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_dataset_packet, final_dataset_packet['Label'],test_size=0.2)\n",
    "    X_train=X_train.drop('Label',axis=1)\n",
    "    X_test=X_test.drop('Label',axis=1)\n",
    "\n",
    "    smt=SMOTE(random_state=42, ratio=float(0.5))\n",
    "    new_X_train, new_y_train=smt.fit_sample(X_train,y_train)\n",
    "    classifier.fit(new_X_train, new_y_train)\n",
    "    #classifier.fit(X_train,y_train)\n",
    "    predicts=classifier.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred=predicts,y_true=y_test).ravel()\n",
    "    precision=float(tp)/(tp+fp)\n",
    "    recall=float(tp)/(tp+fn)\n",
    "    accuracy=float(tp+tn)/(tp+fn+tn+fp)\n",
    "    TN.append(tn)\n",
    "    FP.append(fp)\n",
    "    FN.append(fn)\n",
    "    TP.append(tp)\n",
    "    Precision.append(precision)\n",
    "    Recall.append(recall)\n",
    "    Accuracy.append(accuracy)\n",
    "\n",
    "print('True Negative',np.mean(TN))\n",
    "print('False Positive',np.mean(FP))\n",
    "print('False Negative',np.mean(FN))\n",
    "print('True Positive',np.mean(TP))\n",
    "print('-------------')\n",
    "print( 'Precision :', np.mean(Precision))\n",
    "print ('Recall : ',np.mean(Recall))\n",
    "print ('Accuracy : ',np.mean(Accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using RandmomForest  on Host Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative 102.5\n",
      "False Positive 0.0\n",
      "False Negative 0.5\n",
      "True Positive 2.0\n",
      "-------------\n",
      "Precision : 1.0\n",
      "Recall :  0.8416666666666666\n",
      "Accuracy :  0.9952380952380953\n"
     ]
    }
   ],
   "source": [
    "#Group by SourceIP\n",
    "new_dataset2=new_dataset.groupby('SourceIP')\n",
    "new_dataset2=new_dataset2.sum()\n",
    "new_dataset2=new_dataset2.reset_index()\n",
    "\n",
    "#Assign labels\n",
    "def label(data):\n",
    "    infected={'147.32.84.165','147.32.84.191','147.32.84.192','147.32.84.193','147.32.84.204',\n",
    "             '147.32.84.205','147.32.84.206','147.32.84.207','147.32.84.208','147.32.84.209'}\n",
    "    if data in infected:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "new_dataset2['Label']=new_dataset2['SourceIP'].apply(lambda y: label(y))\n",
    "final_dataset_host=new_dataset2.drop('SourceIP',axis=1)\n",
    "TN=[]\n",
    "FP=[]\n",
    "FN=[]\n",
    "TP=[]\n",
    "Precision=[]\n",
    "Recall=[]\n",
    "Accuracy=[]\n",
    "for i in range(0,10):\n",
    "    classifier=RandomForestClassifier()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_dataset_host, final_dataset_host['Label'],test_size=0.2)\n",
    "    X_train=X_train.drop('Label',axis=1)\n",
    "    X_test=X_test.drop('Label',axis=1)\n",
    "\n",
    "    smt=SMOTE(ratio=float(0.5))\n",
    "    new_X_train, new_y_train=smt.fit_sample(X_train,y_train)\n",
    "    classifier.fit(new_X_train, new_y_train)\n",
    "    predicts=classifier.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(predicts,y_test,labels=[0,1]).ravel()\n",
    "    precision=float(tp)/(tp+fp)\n",
    "    recall=float(tp)/(tp+fn)\n",
    "    accuracy=float(tp+tn)/(tp+fn+tn+fp)\n",
    "    TN.append(tn)\n",
    "    FP.append(fp)\n",
    "    FN.append(fn)\n",
    "    TP.append(tp)\n",
    "    Precision.append(precision)\n",
    "    Recall.append(recall)\n",
    "    Accuracy.append(accuracy)\n",
    "\n",
    "print('True Negative',np.mean(TN))\n",
    "print('False Positive',np.mean(FP))\n",
    "print('False Negative',np.mean(FN))\n",
    "print('True Positive',np.mean(TP))\n",
    "print('-------------')\n",
    "print( 'Precision :', np.mean(Precision))\n",
    "print ('Recall : ',np.mean(Recall))\n",
    "print ('Accuracy : ',np.mean(Accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using DecisionTree on Packet Level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative 4113.9\n",
      "False Positive 15.5\n",
      "False Negative 15.4\n",
      "True Positive 211.2\n",
      "-------------\n",
      "Precision : 0.931017564385256\n",
      "Recall :  0.9317266784167557\n",
      "Accuracy :  0.9929063360881543\n"
     ]
    }
   ],
   "source": [
    "from sklearn import  tree\n",
    "\n",
    "#store ips of the new dataset\n",
    "ips=new_dataset.SourceIP\n",
    "#drop ips for the final dataset\n",
    "final_dataset_packet=new_dataset.drop('SourceIP',axis=1)\n",
    "\n",
    "TN=[]\n",
    "FP=[]\n",
    "FN=[]\n",
    "TP=[]\n",
    "Precision=[]\n",
    "Recall=[]\n",
    "Accuracy=[]\n",
    "for i in range(0,10):\n",
    "    classifier=tree.DecisionTreeClassifier()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_dataset_packet, final_dataset_packet['Label'],test_size=0.2)\n",
    "    X_train=X_train.drop('Label',axis=1)\n",
    "    X_test=X_test.drop('Label',axis=1)\n",
    "\n",
    "    smt=SMOTE(random_state=42, ratio=float(0.5))\n",
    "    new_X_train, new_y_train=smt.fit_sample(X_train,y_train)\n",
    "    classifier.fit(new_X_train, new_y_train)\n",
    "    #classifier.fit(X_train,y_train)\n",
    "    predicts=classifier.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_pred=predicts,y_true=y_test).ravel()\n",
    "    precision=float(tp)/(tp+fp)\n",
    "    recall=float(tp)/(tp+fn)\n",
    "    accuracy=float(tp+tn)/(tp+fn+tn+fp)\n",
    "    TN.append(tn)\n",
    "    FP.append(fp)\n",
    "    FN.append(fn)\n",
    "    TP.append(tp)\n",
    "    Precision.append(precision)\n",
    "    Recall.append(recall)\n",
    "    Accuracy.append(accuracy)\n",
    "\n",
    "print('True Negative',np.mean(TN))\n",
    "print('False Positive',np.mean(FP))\n",
    "print('False Negative',np.mean(FN))\n",
    "print('True Positive',np.mean(TP))\n",
    "print('-------------')\n",
    "print( 'Precision :', np.mean(Precision))\n",
    "print ('Recall : ',np.mean(Recall))\n",
    "print ('Accuracy : ',np.mean(Accuracy))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification using DecisionTree  on Host Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative 102.3\n",
      "False Positive 0.0\n",
      "False Negative 0.6\n",
      "True Positive 2.1\n",
      "-------------\n",
      "Precision : 1.0\n",
      "Recall :  0.8166666666666667\n",
      "Accuracy :  0.9942857142857143\n"
     ]
    }
   ],
   "source": [
    "#Group by SourceIP\n",
    "new_dataset2=new_dataset.groupby('SourceIP')\n",
    "new_dataset2=new_dataset2.sum()\n",
    "new_dataset2=new_dataset2.reset_index()\n",
    "\n",
    "#Assign labels\n",
    "def label(data):\n",
    "    infected={'147.32.84.165','147.32.84.191','147.32.84.192','147.32.84.193','147.32.84.204',\n",
    "             '147.32.84.205','147.32.84.206','147.32.84.207','147.32.84.208','147.32.84.209'}\n",
    "    if data in infected:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "new_dataset2['Label']=new_dataset2['SourceIP'].apply(lambda y: label(y))\n",
    "final_dataset_host=new_dataset2.drop('SourceIP',axis=1)\n",
    "TN=[]\n",
    "FP=[]\n",
    "FN=[]\n",
    "TP=[]\n",
    "Precision=[]\n",
    "Recall=[]\n",
    "Accuracy=[]\n",
    "for i in range(0,10):\n",
    "    classifier=tree.DecisionTreeClassifier()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(final_dataset_host, final_dataset_host['Label'],test_size=0.2)\n",
    "    X_train=X_train.drop('Label',axis=1)\n",
    "    X_test=X_test.drop('Label',axis=1)\n",
    "\n",
    "    smt=SMOTE(ratio=float(0.5))\n",
    "    new_X_train, new_y_train=smt.fit_sample(X_train,y_train)\n",
    "    classifier.fit(new_X_train, new_y_train)\n",
    "    predicts=classifier.predict(X_test)\n",
    "    tn, fp, fn, tp = confusion_matrix(predicts,y_test,labels=[0,1]).ravel()\n",
    "    precision=float(tp)/(tp+fp)\n",
    "    recall=float(tp)/(tp+fn)\n",
    "    accuracy=float(tp+tn)/(tp+fn+tn+fp)\n",
    "    TN.append(tn)\n",
    "    FP.append(fp)\n",
    "    FN.append(fn)\n",
    "    TP.append(tp)\n",
    "    Precision.append(precision)\n",
    "    Recall.append(recall)\n",
    "    Accuracy.append(accuracy)\n",
    "\n",
    "print('True Negative',np.mean(TN))\n",
    "print('False Positive',np.mean(FP))\n",
    "print('False Negative',np.mean(FN))\n",
    "print('True Positive',np.mean(TP))\n",
    "print('-------------')\n",
    "print( 'Precision :', np.mean(Precision))\n",
    "print ('Recall : ',np.mean(Recall))\n",
    "print ('Accuracy : ',np.mean(Accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
